{
  "name": "com.unity.ai.inference",
  "displayName": "Inference Engine",
  "version": "2.2.0",
  "unity": "6000.0",
  "description": "Inference Engine is a neural network inference library. It enables you to import trained neural network models, connect the network inputs and outputs to your game code, and then run them locally in your end-user app. Use cases include capabilities like natural language processing, object recognition, automated game opponents, sensor data classification, and many more.\n\nInference Engine automatically optimizes your network for real-time use to speed up inference. It also allows you to tune your implementation further with tools like frame slicing, quantization, and custom backend (i.e. compute type) dispatching.\n\nVisit https://unity.com/ai for more resources.",
  "dependencies": {
    "com.unity.burst": "1.8.17",
    "com.unity.collections": "2.4.3",
    "com.unity.modules.imageconversion": "1.0.0"
  },
  "_upm": {
    "changelog": "### Added\n- First version of Inference Engine"
  },
  "upmCi": {
    "footprint": "a6ac5209b8a3258a7c0bdca4e7a70156c3b25e2e"
  },
  "documentationUrl": "https://docs.unity3d.com/Packages/com.unity.ai.inference@2.2/manual/index.html",
  "repository": {
    "url": "https://github.cds.internal.unity3d.com/unity/UnityInferenceEngine.git",
    "type": "git",
    "revision": "ce1a84ed8968bcc14439442abaeaaf7f3739e2f3"
  },
  "samples": [
    {
      "displayName": "Convert tensors to textures",
      "description": "Examples of converting tensors to textures.",
      "path": "Samples~/Convert tensors to textures"
    },
    {
      "displayName": "Convert textures to tensors",
      "description": "Examples of converting textures to textures.",
      "path": "Samples~/Convert textures to tensors"
    },
    {
      "displayName": "Copy a texture tensor to the screen",
      "description": "An example of using TextureConverter.RenderToScreen to copy a texture tensor to the screen.",
      "path": "Samples~/Copy a texture tensor to the screen"
    },
    {
      "displayName": "Encrypt a model",
      "description": "Example of serializing an encrypted model to disk using a custom editor window and loading that encrypted model at runtime.",
      "path": "Samples~/Encrypt a model"
    },
    {
      "displayName": "Quantize a model",
      "description": "Example of serializing a quantized model to disk using a custom editor window and loading that quantized model at runtime.",
      "path": "Samples~/Quantize a model"
    },
    {
      "displayName": "Read output asynchronously",
      "description": "Examples of reading the output from a model asynchronously, using compute shaders or Burst.",
      "path": "Samples~/Read output asynchronously"
    },
    {
      "displayName": "Run a model",
      "description": "Examples of running models with different numbers of inputs and outputs.",
      "path": "Samples~/Run a model"
    },
    {
      "displayName": "Run a model a layer at a time",
      "description": "An example of using ScheduleIterable to run a model a layer a time.",
      "path": "Samples~/Run a model a layer at a time"
    },
    {
      "displayName": "Use a compute buffer",
      "description": "An example of using a compute shader to write data to a tensor on the GPU.",
      "path": "Samples~/Use a compute buffer"
    },
    {
      "displayName": "Use Burst to write data",
      "description": "An example of using Burst to write data to a tensor in the Job system.",
      "path": "Samples~/Use a job to write data"
    },
    {
      "displayName": "Use tensor indexing methods",
      "description": "Examples of using tensor indexing methods to get and set tensor values.",
      "path": "Samples~/Use tensor indexing methods"
    },
    {
      "displayName": "Use the functional API with an existing model",
      "description": "An example of using the functional API to extend an existing model.",
      "path": "Samples~/Use the functional API with an existing model"
    }
  ]
}
